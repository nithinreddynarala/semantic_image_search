{"base_dir": "C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search", "timestamp": "2025-12-03T06:13:27.238530Z", "level": "info", "event": "BASE_DIR resolved successfully"}
{"env_path": "C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\.env", "timestamp": "2025-12-03T06:13:27.240532Z", "level": "info", "event": ".env loaded successfully"}
{"value": "C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\images", "timestamp": "2025-12-03T06:13:27.240532Z", "level": "info", "event": "IMAGES_ROOT configured"}
{"value": "C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\data\\query_images", "timestamp": "2025-12-03T06:13:27.241533Z", "level": "info", "event": "QUERY_IMAGE_ROOT configured"}
{"value": "C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\data\\retrieved", "timestamp": "2025-12-03T06:13:27.241533Z", "level": "info", "event": "RETRIEVED_ROOT configured"}
{"value": "ViT-B-32", "timestamp": "2025-12-03T06:13:27.242547Z", "level": "info", "event": "CLIP_MODEL_NAME loaded"}
{"value": "laion2b_s34b_b79k", "timestamp": "2025-12-03T06:13:27.242547Z", "level": "info", "event": "CLIP_CHECKPOINT loaded"}
{"value": "cpu", "timestamp": "2025-12-03T06:13:27.243531Z", "level": "info", "event": "DEVICE selected"}
{"value": "https://f5aeb07c-adb0-4ec0-91a6-0ac26aa51200.us-east-1-1.aws.cloud.qdrant.io:6333", "timestamp": "2025-12-03T06:13:27.243531Z", "level": "info", "event": "QDRANT_URL loaded"}
{"timestamp": "2025-12-03T06:13:27.243531Z", "level": "info", "event": "QDRANT_API_KEY loaded (hidden)"}
{"value": "semantic-search", "timestamp": "2025-12-03T06:13:27.244531Z", "level": "info", "event": "QDRANT_COLLECTION loaded"}
{"value": 512, "timestamp": "2025-12-03T06:13:27.244531Z", "level": "info", "event": "VECTOR_SIZE loaded"}
{"value": "openai/gpt-oss-20b", "timestamp": "2025-12-03T06:13:27.244531Z", "level": "info", "event": "GROQ_MODEL loaded"}
{"timestamp": "2025-12-03T06:13:29.610200Z", "level": "info", "event": "Initializing ImageSearchService"}
{"url": "https://f5aeb07c-adb0-4ec0-91a6-0ac26aa51200.us-east-1-1.aws.cloud.qdrant.io:6333", "using_api_key": true, "timestamp": "2025-12-03T06:13:29.610758Z", "level": "info", "event": "Initializing Qdrant client"}
{"timestamp": "2025-12-03T06:13:35.245951Z", "level": "info", "event": "Qdrant client initialized successfully"}
{"timestamp": "2025-12-03T06:13:35.245951Z", "level": "info", "event": "Fetching existing Qdrant collections..."}
HTTP Request: GET https://f5aeb07c-adb0-4ec0-91a6-0ac26aa51200.us-east-1-1.aws.cloud.qdrant.io:6333/collections "HTTP/1.1 200 OK"
{"collection": "semantic-search", "timestamp": "2025-12-03T06:13:42.047275Z", "level": "info", "event": "Using existing Qdrant collection"}
{"collection": "semantic-search", "retrieved_root": "C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\data\\retrieved", "timestamp": "2025-12-03T06:13:42.047275Z", "level": "info", "event": "ImageSearchService initialized"}
{"timestamp": "2025-12-03T06:13:42.048272Z", "level": "info", "event": "Initializing IndexService..."}
{"timestamp": "2025-12-03T06:13:42.048272Z", "level": "info", "event": "Fetching existing Qdrant collections..."}
HTTP Request: GET https://f5aeb07c-adb0-4ec0-91a6-0ac26aa51200.us-east-1-1.aws.cloud.qdrant.io:6333/collections "HTTP/1.1 200 OK"
{"collection": "semantic-search", "timestamp": "2025-12-03T06:13:42.394368Z", "level": "info", "event": "Using existing Qdrant collection"}
{"collection": "semantic-search", "timestamp": "2025-12-03T06:13:42.394368Z", "level": "info", "event": "IndexService initialized successfully"}
{"timestamp": "2025-12-03T06:13:42.394368Z", "level": "info", "event": "Services initialized successfully"}
{"query": "give me image of yellow flower", "top_k": 5, "category": null, "timestamp": "2025-12-03T06:13:52.906347Z", "level": "info", "event": "Text search request received"}
{"model": "openai/gpt-oss-20b", "timestamp": "2025-12-03T06:13:52.907342Z", "level": "info", "event": "Initializing QueryTranslator..."}
{"timestamp": "2025-12-03T06:13:53.182329Z", "level": "info", "event": "QueryTranslator initialized successfully"}
{"input_query": "give me image of yellow flower", "timestamp": "2025-12-03T06:13:53.183330Z", "level": "info", "event": "Translating query"}
{"timestamp": "2025-12-03T06:13:53.183330Z", "level": "info", "event": "Sending translation prompt to LLM"}
HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
{"original": "give me image of yellow flower", "translated": "bright yellow flower", "timestamp": "2025-12-03T06:13:53.951199Z", "level": "info", "event": "Translation completed"}
{"translated": "bright yellow flower", "timestamp": "2025-12-03T06:13:53.952197Z", "level": "info", "event": "Query translated for text search"}
{"query_text": "bright yellow flower", "top_k": 5, "filter": null, "timestamp": "2025-12-03T06:13:53.952197Z", "level": "info", "event": "Text search started"}
{"model": "ViT-B-32", "checkpoint": "laion2b_s34b_b79k", "device": "cpu", "timestamp": "2025-12-03T06:13:53.952197Z", "level": "info", "event": "Initializing CLIP Embedding Loader"}
Parsing model identifier. Schema: None, Identifier: ViT-B-32
Loaded built-in ViT-B-32 model config.
Instantiating model architecture: CLIP
Loading full pretrained weights from: C:\Users\Narala Nithin\.cache\huggingface\hub\models--laion--CLIP-ViT-B-32-laion2B-s34B-b79K\snapshots\1a25a446712ba5ee05982a381eed697ef9b435cf\open_clip_model.safetensors
Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}
Model ViT-B-32 creation process complete.
Parsing tokenizer identifier. Schema: None, Identifier: ViT-B-32
Attempting to load config from built-in: ViT-B-32
Using default SimpleTokenizer.
{"timestamp": "2025-12-03T06:14:03.345688Z", "level": "info", "event": "CLIP Embedding Model Loaded Successfully"}
{"text_preview": "bright yellow flower", "timestamp": "2025-12-03T06:14:03.346682Z", "level": "info", "event": "Embedding text"}
{"vector_dim": 512, "timestamp": "2025-12-03T06:14:03.458672Z", "level": "info", "event": "Text embedding successful"}
HTTP Request: POST https://f5aeb07c-adb0-4ec0-91a6-0ac26aa51200.us-east-1-1.aws.cloud.qdrant.io:6333/collections/semantic-search/points/query "HTTP/1.1 200 OK"
{"query_text": "bright yellow flower", "total_results": 5, "timestamp": "2025-12-03T06:14:08.341252Z", "level": "info", "event": "Text search completed"}
{"total_results": 5, "timestamp": "2025-12-03T06:14:08.342251Z", "level": "info", "event": "Text search completed"}
{"query": "give me image of wooden furniture", "top_k": 5, "category": null, "timestamp": "2025-12-03T06:14:24.808843Z", "level": "info", "event": "Text search request received"}
{"input_query": "give me image of wooden furniture", "timestamp": "2025-12-03T06:14:24.809841Z", "level": "info", "event": "Translating query"}
{"timestamp": "2025-12-03T06:14:24.809841Z", "level": "info", "event": "Sending translation prompt to LLM"}
HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
{"original": "give me image of wooden furniture", "translated": "wooden furniture displayed", "timestamp": "2025-12-03T06:14:26.930164Z", "level": "info", "event": "Translation completed"}
{"translated": "wooden furniture displayed", "timestamp": "2025-12-03T06:14:26.931163Z", "level": "info", "event": "Query translated for text search"}
{"query_text": "wooden furniture displayed", "top_k": 5, "filter": null, "timestamp": "2025-12-03T06:14:26.931163Z", "level": "info", "event": "Text search started"}
{"text_preview": "wooden furniture displayed", "timestamp": "2025-12-03T06:14:26.931163Z", "level": "info", "event": "Embedding text"}
{"vector_dim": 512, "timestamp": "2025-12-03T06:14:27.033158Z", "level": "info", "event": "Text embedding successful"}
{"query_text": "wooden furniture displayed", "error": "The read operation timed out", "timestamp": "2025-12-03T06:14:33.847979Z", "level": "error", "event": "Text search failed"}
{"query": "give me image of wooden furniture", "error": "Error in [C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\venv\\Lib\\site-packages\\qdrant_client\\http\\api_client.py] at line [136] | Message: Text search failed\nTraceback:\nTraceback (most recent call last):\n  File \"C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 101, in map_httpcore_exceptions\n    yield\n  File \"C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 250, in handle_request\n    resp = self._pool.handle_request(req)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 256, in handle_request\n    raise exc from None\n  File \"C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 236, in handle_request\n    response = connection.handle_request(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\venv\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 103, in handle_request\n    return self._connection.handle_request(request)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py\", line 136, in handle_request\n    raise exc\n  File \"C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py\", line 106, in handle_request\n    ) = self._receive_response_headers(**kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py\", line 177, in _receive_response_headers\n    event = self._receive_event(timeout=timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py\", line 217, in _receive_event\n    data = self._network_stream.read(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\venv\\Lib\\site-packages\\httpcore\\_backends\\sync.py\", line 126, in read\n    with map_exceptions(exc_map):\n  File \"C:\\Users\\Narala Nithin\\AppData\\Roaming\\uv\\python\\cpython-3.11.14-windows-x86_64-none\\Lib\\contextlib.py\", line 158, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\venv\\Lib\\site-packages\\httpcore\\_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ReadTimeout: The read operation timed out\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\venv\\Lib\\site-packages\\qdrant_client\\http\\api_client.py\", line 134, in send_inner\n    response = self._client.send(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\venv\\Lib\\site-packages\\httpx\\_client.py\", line 914, in send\n    response = self._send_handling_auth(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\venv\\Lib\\site-packages\\httpx\\_client.py\", line 942, in _send_handling_auth\n    response = self._send_handling_redirects(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\venv\\Lib\\site-packages\\httpx\\_client.py\", line 979, in _send_handling_redirects\n    response = self._send_single_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\venv\\Lib\\site-packages\\httpx\\_client.py\", line 1014, in _send_single_request\n    response = transport.handle_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 249, in handle_request\n    with map_httpcore_exceptions():\n  File \"C:\\Users\\Narala Nithin\\AppData\\Roaming\\uv\\python\\cpython-3.11.14-windows-x86_64-none\\Lib\\contextlib.py\", line 158, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 118, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ReadTimeout: The read operation timed out\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\semantic_image_search\\backend\\retriever.py\", line 83, in search_by_text\n    results = self.client.query_points(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\venv\\Lib\\site-packages\\qdrant_client\\qdrant_client.py\", line 429, in query_points\n    return self._client.query_points(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\venv\\Lib\\site-packages\\qdrant_client\\qdrant_remote.py\", line 544, in query_points\n    query_result = self.http.search_api.query_points(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\venv\\Lib\\site-packages\\qdrant_client\\http\\api\\search_api.py\", line 783, in query_points\n    return self._build_for_query_points(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\venv\\Lib\\site-packages\\qdrant_client\\http\\api\\search_api.py\", line 181, in _build_for_query_points\n    return self.api_client.request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\venv\\Lib\\site-packages\\qdrant_client\\http\\api_client.py\", line 95, in request\n    return self.send(request, type_)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\venv\\Lib\\site-packages\\qdrant_client\\http\\api_client.py\", line 112, in send\n    response = self.middleware(request, self.send_inner)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\venv\\Lib\\site-packages\\qdrant_client\\http\\api_client.py\", line 250, in __call__\n    return call_next(request)\n           ^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Narala Nithin\\OneDrive\\Desktop\\semantic_image_search\\venv\\Lib\\site-packages\\qdrant_client\\http\\api_client.py\", line 136, in send_inner\n    raise ResponseHandlingException(e)\nqdrant_client.http.exceptions.ResponseHandlingException: The read operation timed out\n", "timestamp": "2025-12-03T06:14:33.873866Z", "level": "error", "event": "Text search failed"}
{"query": "give me image of wooden chair", "top_k": 5, "category": null, "timestamp": "2025-12-03T06:14:56.468453Z", "level": "info", "event": "Text search request received"}
{"input_query": "give me image of wooden chair", "timestamp": "2025-12-03T06:14:56.469447Z", "level": "info", "event": "Translating query"}
{"timestamp": "2025-12-03T06:14:56.469447Z", "level": "info", "event": "Sending translation prompt to LLM"}
HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
{"original": "give me image of wooden chair", "translated": "plain wooden chair", "timestamp": "2025-12-03T06:14:57.088832Z", "level": "info", "event": "Translation completed"}
{"translated": "plain wooden chair", "timestamp": "2025-12-03T06:14:57.088832Z", "level": "info", "event": "Query translated for text search"}
{"query_text": "plain wooden chair", "top_k": 5, "filter": null, "timestamp": "2025-12-03T06:14:57.089831Z", "level": "info", "event": "Text search started"}
{"text_preview": "plain wooden chair", "timestamp": "2025-12-03T06:14:57.089831Z", "level": "info", "event": "Embedding text"}
{"vector_dim": 512, "timestamp": "2025-12-03T06:14:57.182825Z", "level": "info", "event": "Text embedding successful"}
HTTP Request: POST https://f5aeb07c-adb0-4ec0-91a6-0ac26aa51200.us-east-1-1.aws.cloud.qdrant.io:6333/collections/semantic-search/points/query "HTTP/1.1 200 OK"
{"query_text": "plain wooden chair", "total_results": 5, "timestamp": "2025-12-03T06:14:59.672921Z", "level": "info", "event": "Text search completed"}
{"total_results": 5, "timestamp": "2025-12-03T06:14:59.672921Z", "level": "info", "event": "Text search completed"}
